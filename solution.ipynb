{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e40bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ab6ca",
   "metadata": {},
   "source": [
    "### Python code to find the sequence of entropies by slicing through segments of a given file at different positions\n",
    "### Here, we treat the byte sequence as a signal (with amplitude ranging from 0 to 255) and transform it into frequency space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7db318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lempel_ziv_complexity(binary_sequence):\n",
    "    sub_strings = set()\n",
    "    n = len(binary_sequence)\n",
    "\n",
    "    ind = 0\n",
    "    inc = 1\n",
    "    while True:\n",
    "        if ind + inc > len(binary_sequence):\n",
    "            break\n",
    "        sub_str = binary_sequence[ind : ind + inc]\n",
    "        if sub_str in sub_strings:\n",
    "            inc += 1\n",
    "        else:\n",
    "            sub_strings.add(sub_str)\n",
    "            ind += inc\n",
    "            inc = 1\n",
    "    return len(sub_strings)\n",
    "\n",
    "\n",
    "def shannon_entropy(data_classification_sequence):\n",
    "  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    HTML PNG JPEG GIF PDF DOC ELF GZIP AES\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Hold the relative frequency per data file for a given classification sequence\n",
    "    relative_freq_datafile = {\n",
    "        'HTML' : 0, \n",
    "        'PNG' : 0, \n",
    "        'JPEG' : 0, \n",
    "        'GIF': 0,\n",
    "        'PDF' : 0,\n",
    "        'DOC' : 0,\n",
    "        'ELF' : 0,\n",
    "        'GZIP' : 0,\n",
    "        'AES' : 0\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Formula looks like this\n",
    "    # H(S) = −Σ P(Si) log2 (P(Si))\n",
    "    # P(Si) is a bit confusing but, it's the relative frequency of the current char i in the whole string \n",
    "    # as we are iterating on each character in the string. \n",
    "\n",
    "    \n",
    "    # step 1: calculate all the frequency for each characters\n",
    "    for datafile in relative_freq_datafile:\n",
    "        relative_freq_datafile[datafile] = data_classification_sequence.count(datafile) / len(data_classification_sequence)\n",
    "    \n",
    "    # step 2: iterate over each nucleotide and sum up the relative frequency\n",
    "    entropy = 0\n",
    "    for datafile_i in data_classification_sequence:\n",
    "        rel_freq = relative_freq_datafile[datafile_i]\n",
    "        entropy = entropy - (rel_freq * math.log(rel_freq, 2))\n",
    "        \n",
    "    return entropy\n",
    "\n",
    "def shannon_entropy_corrected(data_classification_sequence):\n",
    "    \"\"\"Custom implementation of shannon entropy with a full non-binarized sequence\n",
    "        Formula looks like this\n",
    "        H(S) = −Σ P(Si) log2 (P(Si))\n",
    "        P(Si) here is simply the relative frequency of character HTML,PNG,JPEG,GIF,PDF,DOC,ELF,GZIP,AES or n in the string.\n",
    "    \"\"\"\n",
    "    \n",
    "    entropy = 0\n",
    "    for datafile in {'HTML','PNG','JPEG','GIF','PDF','DOC','ELF','GZIP','AES'}:\n",
    "        rel_freq = data_classification_sequence.count(datafile) / len(data_classification_sequence)\n",
    "        if rel_freq > 0:\n",
    "            entropy = entropy - (rel_freq * math.log(rel_freq, 2))\n",
    "        \n",
    "    return entropy\n",
    "\n",
    "def string_to_binary(string_sequence):\n",
    "    \"\"\"Simple converter from a string sequence to a binary sequence\"\"\"\n",
    "    return ''.join(format(ord(x), 'b') for x in string_sequence)\n",
    "\n",
    "def generate_window(sequence, window_size=256, jump_size=50):\n",
    "    \"\"\" Generator of windowed sequence with specific jump size\n",
    "    Parameters:\n",
    "    sequence (str): a string representing the data\n",
    "    window_size (int): the size of the window we want to return\n",
    "    jump_size (int): how much we want to move the window after each yield\n",
    "    \n",
    "    Yield:\n",
    "    windowed sequence of specific size\n",
    "    \n",
    "    \"\"\"\n",
    "    start = 0\n",
    "    end = window_size\n",
    "    \n",
    "    while end < len(sequence):\n",
    "        yield sequence[start:end]\n",
    "        \n",
    "        start = start + jump_size\n",
    "        end = end + jump_size\n",
    "\n",
    "def generate_lz_sequence(sequence):\n",
    "    \"\"\"helper function to generate a list of Lempel-Ziv complexity metric\"\"\"\n",
    "    lz_sequence = []\n",
    "    for window in generate_window(sequence):\n",
    "        encoded_sequence = string_to_binary(window)\n",
    "        lz = lempel_ziv_complexity(encoded_sequence)\n",
    "        lz_sequence.append(lz)\n",
    "    \n",
    "    return lz_sequence\n",
    "\n",
    "def generate_shannon_sequence(sequence, shannon_fn):\n",
    "    \"\"\"helper function to generate a list of Shannon Entropy metric\"\"\"\n",
    "    se_sequence = []\n",
    "    for window in generate_window(sequence):\n",
    "        se = shannon_fn(window)\n",
    "        se_sequence.append(se)\n",
    "        \n",
    "    return se_sequence\n",
    "\n",
    "def normalize_lz_sequence(lz_sequence, window_size=250):\n",
    "    \"\"\"helper function to normalize a sequence of Lempel-Ziv complexity metric\"\"\"\n",
    "    return [lz/window_size for lz in lz_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0329752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HTML</th>\n",
       "      <th>PNG</th>\n",
       "      <th>JPEG</th>\n",
       "      <th>GIF</th>\n",
       "      <th>PDF</th>\n",
       "      <th>DOC</th>\n",
       "      <th>ELF</th>\n",
       "      <th>GZIP</th>\n",
       "      <th>AES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HTML  PNG  JPEG  GIF  PDF  DOC  ELF  GZIP  AES\n",
       "0        1    0     1    1    1    0    1     0    1\n",
       "1        1    0     1    1    1    0    0     1    1\n",
       "2        0    0     0    0    1    0    1     0    1\n",
       "3        0    1     1    0    1    1    0     1    0\n",
       "4        1    0     1    0    1    0    1     0    0\n",
       "..     ...  ...   ...  ...  ...  ...  ...   ...  ...\n",
       "995      0    0     0    1    0    1    0     1    0\n",
       "996      0    1     0    1    1    1    1     1    0\n",
       "997      0    0     0    1    0    0    1     0    0\n",
       "998      0    0     0    0    1    0    1     1    1\n",
       "999      0    0     0    0    0    1    0     1    1\n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Randomly generated data\n",
    "np.random.seed(1)\n",
    "data3 = pd.DataFrame({\" HTML\" : np.random.randint(low=0, high=2, size=1000),\n",
    "                     \"PNG\"  : np.random.randint(0, 2, size=1000),\n",
    "                      \"JPEG\"  : np.random.randint(0, 2, size=1000),\n",
    "                      \"GIF\"  : np.random.randint(0, 2, size=1000),\n",
    "                      \"PDF\"  : np.random.randint(0, 2, size=1000),\n",
    "                      \"DOC\"  : np.random.randint(0, 2, size=1000),\n",
    "                      \"ELF\"  : np.random.randint(0, 2, size=1000),\n",
    "                      \"GZIP\"  : np.random.randint(0, 2, size=1000),\n",
    "                      \"AES\"  : np.random.randint(0, 2, size=1000)\n",
    "                     })\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cff3e2b",
   "metadata": {},
   "source": [
    "### Preparing Data for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1aa80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the data here,\n",
    "#df = pd.read_csv('#file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "281a02d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming the file has data with column 'filetypes' which contains a sequence of file types we need to classify.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m datafile_list \u001b[38;5;241m=\u001b[39m \u001b[43mdata3\u001b[49m\n\u001b[0;32m      3\u001b[0m main_data_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(datafile_list)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mlen\u001b[39m(main_seq)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data3' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming the file has data with column 'filetypes' which contains a sequence of file types we need to classify.\n",
    "datafile_list = data3\n",
    "main_data_sequence = ''.join(datafile_list)\n",
    "len(main_seq)\n",
    "\n",
    "\n",
    "\n",
    "# Generating Shannon Entropy\n",
    "se_seq = generate_shannon_sequence(main_data_sequence, lambda seq : shannon_entropy(seq))\n",
    "len(se_seq)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generating Corrected Shannon Entropy\n",
    "se_seq_cor = generate_shannon_sequence(main_data_sequence, lambda seq : shannon_entropy_corrected(seq))\n",
    "len(se_seq_cor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generating the lempel-ziv sequence with window of 256 datafile formats and jumps of 50 datafiles\n",
    "lz_sequence = generate_lz_sequence(main_data_sequence)\n",
    "len(lz_seq)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Normalizing the LZ complexity between 0 and 1\n",
    "n_lz_sequence = normalize_lz_sequence(lz_sequence, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this project, i will generate random dummy data\n",
    "x_train = np.random.random((1000, 9))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(9, size=(1000,1)),num_classes=9)\n",
    "x_test = np.random.random((100, 9))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(9, size=(1000,1)),num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3704f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fdb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f32481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have an existing dataset,\n",
    "\n",
    "# Splitting the dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim = 9))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.09, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8276edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_classentrepy',\n",
    "             optimizer = sgd,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99acac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=1000, batch_size=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a44733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
